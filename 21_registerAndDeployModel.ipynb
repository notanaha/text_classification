{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>モデルの登録とエンドをデプロイします </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>モデルを登録します</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: When model_path is set to a directory, you can use the child_paths parameter to include\n",
    "#      only some of the files from the directory\n",
    "model = Model.register(model_path = \"./models\",\n",
    "                       model_name = \"text_classifier_lstm\",\n",
    "                       model_framework=Model.Framework.PYTORCH,\n",
    "                       model_framework_version=torch.__version__,\n",
    "                       description = \"text claasifier by lstm\",\n",
    "                       tags={'name': \"text classifier lstm\", 'ver': \"initial\"},\n",
    "                       workspace = workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>score.py ファイルを準備します</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "from azureml.core.model import Model\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def init():\n",
    "    \n",
    "    class LitTrainClassifier(pl.LightningModule):\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            y_hat = self.forward(x)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "            return loss\n",
    "\n",
    "    class LitValidationClassifier(pl.LightningModule):\n",
    "\n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            y_hat = self.forward(x)\n",
    "            y_pred = torch.argmax(y_hat, dim=1)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            acc = accuracy(y_pred, y)\n",
    "            self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "            self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "            return loss\n",
    "\n",
    "    class LitTestClassifier(pl.LightningModule):\n",
    "\n",
    "        def test_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            y_hat = self.forward(x)\n",
    "            y_pred = torch.argmax(y_hat, dim=1)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            acc = accuracy(y_pred, y)\n",
    "            self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "            self.log('test_acc', acc, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "            return loss\n",
    "\n",
    "    class LSTMModel(LitTrainClassifier, LitValidationClassifier, LitTestClassifier):\n",
    "\n",
    "        def __init__(self, vocab_size=7295, embedding_dim=200, hidden_dim=100, layer_dim=2, output_dim=9, drop_out=0.3):\n",
    "            super(LSTMModel, self).__init__()\n",
    "\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.layer_dim = layer_dim\n",
    "\n",
    "            self.lstm = torch.nn.LSTM(input_size = embedding_dim,\n",
    "                                      hidden_size = hidden_dim,\n",
    "                                      num_layers = layer_dim,\n",
    "                                      dropout = drop_out,\n",
    "                                      batch_first=True)    \n",
    "\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.embeddings(x)        \n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            out = self.fc(lstm_out[:, -1, :])\n",
    "            return out\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            return torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "        \n",
    "    global net\n",
    "    model_filename = '/text_classifier_lstm.pt'\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'models')\n",
    "\n",
    "    net = LSTMModel()\n",
    "    net.load_state_dict(torch.load(model_path + model_filename))\n",
    "    \n",
    "    \n",
    "def run(raw_data):\n",
    "    x = np.array(json.loads(raw_data)['data'], dtype=np.int64)\n",
    "    x = torch.tensor(x, dtype=torch.int64)\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    \n",
    "    y_hat = net.forward(x)\n",
    "    y_pred = torch.argmax(y_hat)\n",
    "    \n",
    "    return y_pred.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Conda 環境を指定し、yml ファイルを書出します</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('numpy')\n",
    "cd.add_pip_package(\"azureml-defaults\")\n",
    "cd.add_pip_package('torch==1.8.1')\n",
    "cd.add_pip_package('pytorch-lightning==1.3.1')\n",
    "cd.save_to_file(base_directory='./', conda_file_path='text_classifier_lstm.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Web Service endpoint をデプロイします</h4>\n",
    "<br>10~15分くらいかかります</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment.from_conda_specification(name=\"text_classifier_lstm\", file_path=\"./text_classifier_lstm.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=3, \n",
    "                                               tags={'name':'text_classifier_lstm', 'framework': 'PyTorch'},\n",
    "                                               description='text classifier lstm')\n",
    "\n",
    "service = Model.deploy(workspace=workspace,\n",
    "                           name='text-classifier-lstm', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig, overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Endpoint URI を確認します</h4>\r\n",
    "\r\n",
    "- URI は次のステップで使うのでコピーしておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_uri = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_env)",
   "language": "python",
   "name": "text_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}