{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2>文章を単語IDで表現する</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>事前加工したテキストファイルを読込みます</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\r\n",
    "document_file_loaded = open(\"./document1.pkl\",\"rb\")\r\n",
    "documents = pickle.load(document_file_loaded)\r\n",
    "labels_file_loaded = open(\"./label1.pkl\",\"rb\")\r\n",
    "labels = pickle.load(labels_file_loaded)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>１番目のファイルの先頭部分を表示して内容を確認してみます</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "documents[0][:200]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(labels[0])\r\n",
    "print(labels[-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>MeCab をインポートします</h3>\r\n",
    "\r\n",
    "<h5>MeCab 関連の処理はこちらを参考にしました</h5>\r\n",
    "\r\n",
    "- [キカガク：自然言語処理の基礎（PyTorch）](https://free.kikagaku.ai/tutorial/basic_of_nlp/learn/pytorch_text_classification)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import MeCab"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mecab = MeCab.Tagger(\"-d /var/lib/mecab/dic/ipadic-utf8 -Ochasen\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>テキストから名詞だけを抽出する</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mecab.parse('ブートキャンプする').split('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>'EOS' と ' ' を取り除き、タブを取り除きます。最後に '名詞' を含む行の先頭文字を取得します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def list_nouns(sentense):\r\n",
    "    nouns = []\r\n",
    "    word_pieces = mecab.parse(sentense)\r\n",
    "    word_pieces = word_pieces.split('\\n')[:-2]\r\n",
    "    for piece in word_pieces:\r\n",
    "        item = piece.split('\\t')\r\n",
    "        if '名詞' in item[3]:        # <=== changed to 4 for default output format\r\n",
    "            nouns.append(item[0])\r\n",
    "    return nouns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pieces = []\r\n",
    "for document in documents:\r\n",
    "    nouns = list_nouns(document)\r\n",
    "    pieces.append(nouns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>先頭文書の名詞を確認します</h4>\n",
    "\n",
    "- 文書は全部で 7367 あります"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(pieces[0][:10])\r\n",
    "print('ドキュメント数 ' + str(len(pieces)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>名詞の辞書を作成します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim import corpora, matutils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dictionary_0 = corpora.Dictionary(pieces)\r\n",
    "print('名詞の数 ' + str(len(dictionary_0)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>出現回数が 20以下の名詞を削除</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dictionary_0.filter_extremes(no_below=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('名詞の数 ' + str(len(dictionary_0)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>単語と ID の関係を確認します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dictionary_0.token2id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>文書に含まれる名詞全体のベクトル表現を作ってみます（各要素は名詞の発生件数で、名詞が発生した順序は考慮されません）</h4>\n",
    "\n",
    "- 今回は利用しませんが知ってると便利です"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_pieces = len(dictionary_0)\r\n",
    "x_token = []\r\n",
    "for piece in pieces:\r\n",
    "    bow = dictionary_0.doc2bow(piece)\r\n",
    "    vec = matutils.corpus2dense([bow], num_pieces).T[0]\r\n",
    "    x_token.append(vec)\r\n",
    "x_token[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>パディング用の意味のない単語を追加してマージします（'pad'という単語を 0 にアサインします）</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pad_corpus = [['pad']]   # for pading token\r\n",
    "dictionary = corpora.Dictionary(pad_corpus)\r\n",
    "dictionary.token2id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dictionary.merge_with(dictionary_0)\r\n",
    "dictionary.token2id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>文書（名詞）を辞書の名詞 ID で置換します</h3>\n",
    "<h4>辞書にない単語は無視します</h4>\n",
    "\n",
    "- -1 は辞書にない単語（出現回数が 20 以下）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_idx = []\r\n",
    "for piece in pieces:\r\n",
    "    idx_0 = dictionary.doc2idx(piece)\r\n",
    "    idx_1 = [a for a in idx_0 if a  != -1]\r\n",
    "    x_idx.append(idx_1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 最初の文書（名詞）の長さと、辞書の名詞 ID で置換された内容を確認します"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(x_idx[0]))\n",
    "print(x_idx[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>もっとも長いリストを確認します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "l = [len(a) for a in x_idx]\n",
    "max_len = max(l)\n",
    "max_len_idx =l.index(max_len)\n",
    "print('max length', max_len)\n",
    "print('max index', max_len_idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>最も長い文書に長さを統一します</h4>\n",
    "\n",
    "- その際、パディング文字 id 0 を使います"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_pad = []\n",
    "for idx in x_idx:\n",
    "    for a in range(max_len - len(idx)):\n",
    "        idx.append(0)\n",
    "    x_pad.append(idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>先頭の文書で確認します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(x_pad[0]))\n",
    "print(x_pad[0][:200])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>今回はメモリ節約のために長さを切詰めます</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sentence_size = 200\n",
    "x_pad2 = []\n",
    "for idx in x_idx:\n",
    "    n = len(idx)\n",
    "    if n > sentence_size:        \n",
    "        for a in range(0, n - sentence_size ):\n",
    "            idx.pop()\n",
    "    else:\n",
    "        for a in range(sentence_size - n):\n",
    "            idx.append(0)  # idx.insert(0, 0)\n",
    "    x_pad2.append(idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(x_pad2[0]))\n",
    "print(x_pad2[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>長さを確認します</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "l_pad2 = [len(a) for a in x_pad2]\n",
    "print('max length', max(l_pad2))\n",
    "print('min length', min(l_pad2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>名詞の数を確認します</h3>\n",
    "\n",
    "- この vocab_size はモデルトレーニングで指定する値になります</h4>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocab_size = len(dictionary)\n",
    "print(vocab_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>ここまでのデータを一旦エクスポートします</h4>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "x = np.array(x_pad2)\n",
    "y = np.array(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.savez('docdata1', x, y)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_env)",
   "language": "python",
   "name": "text_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}